{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agile Education Analyzer - Quick Start Guide\n",
    "\n",
    "This notebook demonstrates the basic usage of the Agile Education Analysis Framework for analyzing Ukrainian educational transcripts.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Make sure you have installed the package:\n",
    "```bash\n",
    "pip install -e .\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from agile_education_analyzer import (\n",
    "    UkrainianDiscourseDetector,\n",
    "    StatisticalAnalyzer,\n",
    "    ResearchVisualizer,\n",
    "    ResearchOutputGenerator,\n",
    "    setup_logger\n",
    ")\n",
    "from agile_education_analyzer.data_structures import TranscriptSegment\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "\n",
    "# Setup logging\n",
    "logger = setup_logger(level='INFO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Ukrainian Discourse Pattern Detection\n",
    "\n",
    "Detect questions, confusion, understanding confirmations, and code-switching in Ukrainian text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize detector\n",
    "detector = UkrainianDiscourseDetector()\n",
    "\n",
    "# Sample Ukrainian texts\n",
    "texts = [\n",
    "    \"Що таке спринт?\",\n",
    "    \"Не розумію як це працює\",\n",
    "    \"Зрозуміло, дякую\",\n",
    "    \"Використайте function для створення component\"\n",
    "]\n",
    "\n",
    "# Detect patterns\n",
    "for text in texts:\n",
    "    print(f\"\\nText: {text}\")\n",
    "    print(f\"Question: {detector.detect_questions(text)}\")\n",
    "    print(f\"Confusion: {detector.detect_confusion(text)}\")\n",
    "    print(f\"Understanding: {detector.detect_understanding(text)}\")\n",
    "    print(f\"Code-switching: {detector.detect_code_switching(text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyze Transcript Segments\n",
    "\n",
    "Apply comprehensive pattern detection to transcript segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample segments\n",
    "segments = [\n",
    "    TranscriptSegment(\n",
    "        index=0,\n",
    "        start_time=timedelta(seconds=0),\n",
    "        end_time=timedelta(seconds=5),\n",
    "        text=\"Що таке гнучка розробка?\",\n",
    "        speaker=\"Student_1\",\n",
    "        speaker_role=\"student\"\n",
    "    ),\n",
    "    TranscriptSegment(\n",
    "        index=1,\n",
    "        start_time=timedelta(seconds=6),\n",
    "        end_time=timedelta(seconds=12),\n",
    "        text=\"Пояснюю: agile це методологія розробки\",\n",
    "        speaker=\"Teacher\",\n",
    "        speaker_role=\"teacher\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Analyze each segment\n",
    "for segment in segments:\n",
    "    analyzed = detector.analyze_segment(segment)\n",
    "    print(f\"\\n{analyzed.speaker}: {analyzed.text}\")\n",
    "    print(f\"  Is Question: {analyzed.is_question}\")\n",
    "    print(f\"  Is Confusion: {analyzed.is_confusion}\")\n",
    "    print(f\"  Technical Terms: {analyzed.technical_terms}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Statistical Analysis\n",
    "\n",
    "Perform rigorous statistical testing appropriate for educational research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize statistical analyzer\n",
    "stats = StatisticalAnalyzer(significance_level=0.05, use_bonferroni=True)\n",
    "\n",
    "# Sample data: participation rates across sprints\n",
    "data = pd.DataFrame({\n",
    "    'sprint_number': [1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
    "    'participation_rate': [0.45, 0.52, 0.48, 0.61, 0.58, 0.63, 0.72, 0.68, 0.75]\n",
    "})\n",
    "\n",
    "# Compare across sprints\n",
    "results = stats.compare_sprints(data, 'participation_rate')\n",
    "print(\"\\nKruskal-Wallis Test Results:\")\n",
    "print(results['kruskal_wallis'])\n",
    "\n",
    "if 'pairwise_comparisons' in results:\n",
    "    print(\"\\nPairwise Comparisons:\")\n",
    "    for comparison in results['pairwise_comparisons']:\n",
    "        print(f\"  Sprint {comparison['sprint_pair'][0]} vs {comparison['sprint_pair'][1]}: \"\n",
    "              f\"p={comparison['p_value']:.4f}, d={comparison['cohens_d']:.3f} \"\n",
    "              f\"({comparison['effect_interpretation']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualization\n",
    "\n",
    "Create publication-ready visualizations with Ukrainian text support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize visualizer\n",
    "viz = ResearchVisualizer(dpi=150)  # Lower DPI for notebook display\n",
    "\n",
    "# Create sample engagement data\n",
    "engagement_data = pd.DataFrame({\n",
    "    'sprint_number': [1, 2, 3],\n",
    "    'avg_questions_per_student': [2.1, 3.4, 4.2],\n",
    "    'participation_rate': [0.48, 0.61, 0.72],\n",
    "    'confusion_rate': [0.15, 0.10, 0.05],\n",
    "    'understanding_rate': [0.65, 0.75, 0.85]\n",
    "})\n",
    "\n",
    "# Plot engagement evolution\n",
    "viz.plot_engagement_evolution(engagement_data, 'engagement_evolution.png')\n",
    "print(\"\\nEngagement evolution plot saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Research Outputs\n",
    "\n",
    "Generate LaTeX tables and extract quotations for academic papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize output generator\n",
    "output_gen = ResearchOutputGenerator()\n",
    "\n",
    "# Generate LaTeX table from statistical results\n",
    "latex_table = output_gen.generate_statistical_test_table(results)\n",
    "print(\"\\nLaTeX Table for Statistical Results:\")\n",
    "print(latex_table)\n",
    "\n",
    "# Extract quotations\n",
    "quotations = output_gen.extract_quotations(segments, criteria='questions', max_quotes=5)\n",
    "print(\"\\nExtracted Quotations:\")\n",
    "for i, quote in enumerate(quotations, 1):\n",
    "    print(f\"\\n{i}. {output_gen.format_quotation_latex(quote)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Complete Analysis Workflow\n",
    "\n",
    "For analyzing actual VTT files, you would typically:\n",
    "\n",
    "```python\n",
    "from agile_education_analyzer.vtt_processor import VTTProcessor\n",
    "from agile_education_analyzer.speaker_diarization import SpeakerDiarization\n",
    "\n",
    "# Initialize processors\n",
    "vtt_processor = VTTProcessor()\n",
    "speaker_diarizer = SpeakerDiarization()\n",
    "\n",
    "# Parse VTT file\n",
    "segments = vtt_processor.parse_vtt_file('transcripts/Web2.П01.Вступ до гнучкої розробки.vtt')\n",
    "\n",
    "# Identify speakers\n",
    "segments = speaker_diarizer.identify_speakers(segments)\n",
    "\n",
    "# Analyze discourse patterns\n",
    "for segment in segments:\n",
    "    detector.analyze_segment(segment)\n",
    "\n",
    "# Generate complete analysis and visualizations\n",
    "# ... (continue with statistical analysis, visualization, etc.)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Explore the full API** in the `USAGE_GUIDE.md`\n",
    "2. **Read CLAUDE.md** for detailed guidance on working with this framework\n",
    "3. **Check the tests** in `tests/` directory for more usage examples\n",
    "4. **Examine `run_analysis_example.py`** for complete analysis pipelines\n",
    "\n",
    "For questions or issues, refer to the documentation or create an issue on GitHub."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
